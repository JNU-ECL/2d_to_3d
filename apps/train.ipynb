{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "from dataset import *\n",
    "from loss import create_criterion\n",
    "\n",
    "from model import get_pose_net\n",
    "import argparse\n",
    "import glob\n",
    "import json\n",
    "import multiprocessing\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import random\n",
    "import re\n",
    "import platform\n",
    "from importlib import import_module\n",
    "from pathlib import Path\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "import wandb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR,LambdaLR\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Optional, Dict, Union\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import smplx\n",
    "\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from collections import OrderedDict\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "args=easydict.EasyDict({\n",
    "    # Data and model checkpoints directories\n",
    "    'name':'exp',\n",
    "    'seed':42,\n",
    "    'epochs':5,\n",
    "    'dataset':'temp_dataset',\n",
    "    'augmentation':'BaseAugmentation', \n",
    "    'resize':[512,512], \n",
    "    'batch_size':20, \n",
    "    'valid_batch_size':20, \n",
    "    'model':'TempModel', \n",
    "    'optimizer':'Adam', \n",
    "    'log_interval':5,\n",
    "    'lr':0.00025, \n",
    "    'val_ratio':0.2,\n",
    "    'criterion_2':'depth_criterion',\n",
    "    'criterion_3':'projection_criterion',\n",
    "    'criterion_4':'cam_criterion',\n",
    "    'criterion_5':'joint_3d_criterion',\n",
    "    'criterion_6':'heatmap_criterion',\n",
    "    'criterion_7':'heatmap_proj_criterion',\n",
    "    'lr_decay_step':6000, \n",
    "    'data_dir':'/dataset/egodataset', \n",
    "    'model_dir':'/workspace/2d_to_3d/apps',\n",
    "    'smpl_dir':'/workspace/2d_to_3d/model/smpl',\n",
    "    'model_pretrained_path':'/workspace/2d_to_3d/apps/exp71\\last.pth'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_={\n",
    "    'criterion_weight' : 1,\n",
    "    'criterion_weight' : 1,\n",
    "    'criterion_weight' : 1,\n",
    "    'criterion_weight' : 1,\n",
    "    'criterion_weight' : 1,\n",
    "    'criterion_weight' : 1,\n",
    "    'lr_decay_step' : 20,\n",
    "    'lr' : 0.001,\n",
    "    'val_ratio' : 0.2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "        \n",
    "def increment_path(path, exist_ok=False):\n",
    "    \"\"\" Automatically increment path, i.e. runs/exp --> runs/exp0, runs/exp1 etc.\n",
    "\n",
    "    Args:\n",
    "        path (str or pathlib.Path): f\"{model_dir}/{args.name}\".\n",
    "        exist_ok (bool): whether increment path (increment if False).\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    if (path.exists() and exist_ok) or (not path.exists()):\n",
    "        return str(path)\n",
    "    else:\n",
    "        dirs = glob.glob(f\"{path}*\")\n",
    "        matches = [re.search(rf\"%s(\\d+)\" % path.stem, d) for d in dirs]\n",
    "        i = [int(m.groups()[0]) for m in matches if m]\n",
    "        n = max(i) + 1 if i else 2\n",
    "        return f\"{path}{n}\"\n",
    "\n",
    "def nan_detect_hook(module,input,output,label_info,label):\n",
    "    if torch.isnan(output).any():\n",
    "        print(f'nan : in {module}')\n",
    "        sys.exit(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_token = '/' if 'Linux' in platform.platform() else '\\\\'\n",
    "# model_folder = r'C:\\Users\\user\\Documents\\GitHub\\smplx'\n",
    "# model_type = 'smpl'\n",
    "# plot_joints = 'true'\n",
    "# use_face_contour = False\n",
    "# gender = 'female'\n",
    "# ext = 'npz'\n",
    "# num_betas = 10\n",
    "# num_expression_coeffs = 10\n",
    "\n",
    "ktree_pred = [-1,  0,  0,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9,  9,  9, 12, 13,\n",
    "\t\t14, 16, 17, 18, 19, 20, 21, 15, 20, 25, 26, 20, 28, 29, 20, 31, 32,\n",
    "\t\t20, 34, 35, 20, 37, 38, 21, 40, 41, 21, 43, 44, 21, 46, 47, 21, 49,\n",
    "\t\t50, 21, 52, 53]\n",
    "\n",
    "ktree_label = [-1,0,0,0,1,2,3,4,5,6,7,8,9,12,12,13,14,15,16,17,18,12]\n",
    "xR_2_SMPL=[2,31,61,62,27,57,63,4,34,64,29,59,0,28,58,1,3,33,5,35,6,36,11,41]\n",
    "skip_num = []\n",
    "\n",
    "\"\"\"\n",
    "def joint_2d_viewer(input_images, joints, labels, infos):\n",
    "\ttemp_input_images = input_images.clone().detach().cpu()\n",
    "\ttemp_joints = joints.clone().detach().cpu()\n",
    "\ttemp_labels = labels.clone().detach().cpu()\n",
    "\ttemp_infos = infos\n",
    "\tfig,ax = plt.subplots(len(labels),3,figsize=(10, 70))\n",
    "   \n",
    "\tfor i,(input_image,pred_joint,label,info) in enumerate(zip(temp_input_images,temp_joints,temp_labels,temp_infos)):\n",
    "\t\t# ax = fig.add_subplot(len(input_images),1,i)\n",
    "\t\t# ax.scatter(joints[:22, 0], joints[:22, 1], -joints[:22, 2], color='r')\n",
    "\n",
    "\t\tpred_joint = pred_joint.numpy()\n",
    "\t\tlabel = label.squeeze(0).numpy()\n",
    "\t\t# # SMPL joints line plot\n",
    "\t\tfor j in reversed(range(22)):\n",
    "\t\t\tif not j:break\n",
    "\t\t\tif j in skip_num : continue\n",
    "\t\t\tpred_joint_line_x=[pred_joint[j,0],pred_joint[ktree_pred[j],0]]\n",
    "\t\t\tpred_joint_line_y=[pred_joint[j,1],pred_joint[ktree_pred[j],1]]\n",
    "\t\t\tlabel_joint_line_x=[label[j,0],label[ktree_label[j],0]]\n",
    "\t\t\tlabel_joint_line_y=[label[j,1],label[ktree_label[j],1]]\n",
    "\t\t\tax[i][1].plot(pred_joint_line_x,pred_joint_line_y)\n",
    "\t\t\tax[i][2].plot(label_joint_line_x,label_joint_line_y)\n",
    "\n",
    "\t\tax[i][0].set_aspect('equal')\n",
    "\t\tax[i][1].set_aspect('equal')\n",
    "\t\tax[i][2].set_aspect('equal')\n",
    "\t\tax[i][1].view_init(-30,60,180)\n",
    "\t\tax[i][2].view_init(-30,60,180)\n",
    "\t\t# ax[i][1].set_xlabel('x')\n",
    "\t\t# ax[i][1].set_ylabel('y')\n",
    "\t\t\n",
    "\n",
    "\n",
    "\t\tinput_image=to_pil_image(input_image)\n",
    "\t\tax[i][0].imshow(input_image)\n",
    "\n",
    "\t\tax[i][0].set_title(info.split(split_token)[-1])\n",
    "\t\tax[i][1].set_title('pred_2d_joint')\n",
    "\t\tax[i][2].set_title('joint_GT')\n",
    "\t# plt.show()\n",
    "\n",
    "\treturn fig\n",
    "\"\"\"\n",
    "\n",
    "def fisheye_joint_2d_viewer(input_images, joints, labels, infos, feature_size = (512,512)):\n",
    "\ttemp_input_images = input_images.clone().detach().cpu()\n",
    "\ttemp_joints = joints.clone().detach().cpu()\n",
    "\ttemp_labels = labels.clone().detach().cpu()\n",
    "\n",
    "\tfig,ax = plt.subplots(len(labels),3,figsize=(10, 70))\n",
    "   \n",
    "\tfor i,(input_image,pred_joint,label,info) in enumerate(zip(temp_input_images,temp_joints,temp_labels,infos)):\n",
    "\t\t# ax = fig.add_subplot(len(input_images),1,i)\n",
    "\t\t# ax.scatter(joints[:22, 0], joints[:22, 1], -joints[:22, 2], color='r')\n",
    "\t\tlabel = label.squeeze(0)\n",
    "\t\t# SMPL_form_pred=[]\n",
    "\t\t# SMPL_form_GT=[]\n",
    "\t\t# for xR_idx in xR_2_SMPL:\n",
    "\t\t#     SMPL_form_pred.append(pred_joint[xR_idx])\n",
    "\t\t#     SMPL_form_GT.append(label[xR_idx])\n",
    "\t\t# SMPL_form_pred=torch.stack(SMPL_form_pred)    \n",
    "\t\t# SMPL_form_GT=torch.stack(SMPL_form_GT)\n",
    "\t\t# pred_joint = SMPL_form_pred\n",
    "\t\t# label = SMPL_form_GT\n",
    "\t\t# # SMPL joints line plot\n",
    "\t\tfor j in reversed(range(len(pred_joint))):\n",
    "\t\t\tif not j:break\n",
    "\t\t\tif j in skip_num : continue\n",
    "\t\t\tpred_joint_line_x=[pred_joint[j,0],pred_joint[ktree_label[j],0]]\n",
    "\t\t\tpred_joint_line_y=[pred_joint[j,1],pred_joint[ktree_label[j],1]]\n",
    "\t\t\tlabel_joint_line_x=[label[j,0],label[ktree_label[j],0]]\n",
    "\t\t\tlabel_joint_line_y=[label[j,1],label[ktree_label[j],1]]\n",
    "\t\t\tax[i][1].plot(pred_joint_line_x,pred_joint_line_y)\n",
    "\t\t\tax[i][2].plot(label_joint_line_x,label_joint_line_y)\n",
    "\n",
    "\t\tax[i][0].set_aspect('equal')\n",
    "\t\tax[i][1].set_aspect('equal')\n",
    "\t\tax[i][2].set_aspect('equal')\n",
    "  \n",
    "\t\tax[i][1].set_xlim(0,feature_size[1])\n",
    "\t\tax[i][1].set_ylim(0,feature_size[0])\n",
    "\t\tax[i][2].set_xlim(0,feature_size[1])\n",
    "\t\tax[i][2].set_ylim(0,feature_size[0])\n",
    "\t\tax[i][1].invert_yaxis()\n",
    "\t\tax[i][2].invert_yaxis()\n",
    "\t\t# ax[i][1].set_xlabel('x')\n",
    "\t\t# ax[i][1].set_ylabel('y')\n",
    "\t\t\n",
    "\n",
    "\n",
    "\t\tinput_image=to_pil_image(input_image)\n",
    "\t\tax[i][0].imshow(input_image)\n",
    "\n",
    "\t\tax[i][0].set_title(info.split(split_token)[-1])\n",
    "\t\tax[i][1].set_title('pred_fisheye_joint')\n",
    "\t\tax[i][2].set_title('fisheye_GT')\n",
    "\n",
    "\n",
    "\n",
    "\t# plt.show()\n",
    "\n",
    "\treturn fig\n",
    "\n",
    "\n",
    "def joint_3d_viewer(input_images, joints, labels, infos):\n",
    "\ttemp_input_images = input_images.clone().detach().cpu()\n",
    "\ttemp_labels = labels.clone().detach().cpu()\n",
    "\ttemp_joints = joints.clone().detach().cpu()\n",
    "\tfig,ax = plt.subplots(len(labels),3,figsize=(10,70),subplot_kw={\"projection\":\"3d\"})\n",
    "\tfor i in range(len(labels)):\n",
    "\t\trows, cols, start, stop = ax[i][0].get_subplotspec().get_geometry()\n",
    "\t\tax[i][0].remove()\n",
    "\t\tax[i][0] = fig.add_subplot(rows,cols,start+1)\n",
    "\t\n",
    "\tfor i,(input_image, joint, label, info) in enumerate(zip(temp_input_images, temp_joints, temp_labels, infos)):\n",
    "\t\tinput_image=to_pil_image(input_image)\n",
    "\n",
    "\t\t# SMPL joints line plot\n",
    "\t\tfor j in reversed(range(len(joint))):\n",
    "\t\t\tif not j:break\n",
    "\t\t\tif j in skip_num : continue\n",
    "\t\t\tpred_joint_line_x=[joint[j,0],joint[ktree_label[j],0]]\n",
    "\t\t\tpred_joint_line_y=[joint[j,1],joint[ktree_label[j],1]]\n",
    "\t\t\tpred_joint_line_z=[joint[j,2],joint[ktree_label[j],2]]\n",
    "\t\t\tax[i][1].plot(pred_joint_line_x, pred_joint_line_y, pred_joint_line_z)\n",
    "\t\t\tlabel_joint_line_x=[label[j,0],label[ktree_label[j],0]]\n",
    "\t\t\tlabel_joint_line_y=[label[j,1],label[ktree_label[j],1]]\n",
    "\t\t\tlabel_joint_line_z=[label[j,2],label[ktree_label[j],2]] \n",
    "\t\t\tax[i][2].plot(label_joint_line_x,label_joint_line_y, label_joint_line_z)\n",
    "\n",
    "\t\t# for j in reversed(range(len(label))):\n",
    "\t\t# \tif not j:break\n",
    "\t\t# \tif j in skip_num : continue\n",
    "\n",
    "\t\t# \tlabel_joint_line_x=[label[j,0],label[ktree_label[j],0]]\n",
    "\t\t# \tlabel_joint_line_y=[label[j,1],label[ktree_label[j],1]]\n",
    "\t\t# \tlabel_joint_line_z=[label[j,2],label[ktree_label[j],2]] \n",
    "\n",
    "\t\t# \tax[i][2].plot(label_joint_line_x,label_joint_line_y, label_joint_line_z)\n",
    "\t\t\n",
    "\t\tax[i][0].set_aspect('equal')\n",
    "\t\tax[i][1].set_aspect('equal')\n",
    "\t\tax[i][2].set_aspect('equal')\n",
    "\t\tax[i][1].view_init(-30,60,180)\n",
    "\t\tax[i][2].view_init(-30,60,180)\n",
    "\t\tax[i][1].set_xlabel('x')\n",
    "\t\tax[i][1].set_ylabel('y')\n",
    "\t\tax[i][1].set_zlabel('z')\n",
    "\t\tax[i][2].set_ylabel('y')\n",
    "\t\tax[i][2].set_xlabel('x')\n",
    "\t\tax[i][2].set_zlabel('z')\n",
    "\t\t\n",
    "\t\tax[i][0].imshow(input_image)\n",
    "\n",
    "\t\tax[i][0].set_title(info.split(split_token)[-1])\n",
    "\t\tax[i][1].set_title('pred_3d_joint')\n",
    "\t\tax[i][2].set_title('3d_joint_GT')\n",
    "\t# plt.show()\n",
    "\treturn fig\n",
    "\n",
    "def depth_viewer(input_images, features, labels, infos):\n",
    "\ttemp_input_images=input_images.clone().detach().cpu()\n",
    "\ttemp_features=features.clone().detach().cpu()\n",
    "\ttemp_labels=labels.clone().detach().cpu()\n",
    "\tfig,ax = plt.subplots(len(labels),3,figsize=(10, 70))\n",
    "\n",
    "\tfor i,(input_image, feature, label,info) in enumerate(zip(temp_input_images, temp_features, temp_labels,infos)):\n",
    "\n",
    "\t\tinput_image=to_pil_image(input_image)\n",
    "\t\tfeature=to_pil_image(feature)\n",
    "\t\tlabel=to_pil_image(label)\n",
    "\t\tax[i][0].set_title(info.split(split_token)[-1])\n",
    "\t\tax[i][0].imshow(input_image )\n",
    "\t\tax[i][1].set_title('pred_depth_feature')\n",
    "\t\tax[i][1].imshow(feature)\n",
    "\t\tax[i][2].set_title('depth_GT')\n",
    "\t\tax[i][2].imshow(label)\n",
    "\n",
    "\n",
    "\t# plt.show()\n",
    "\n",
    "\treturn fig  \n",
    "\n",
    "def heatmap_viewer(input_images, heatmaps, labels, infos):\n",
    "\ttemp_input_images = input_images.clone().detach()\n",
    "\ttemp_heatmaps = heatmaps.clone().detach().cpu()\n",
    "\ttemp_labels = labels.clone().detach().cpu()\n",
    "\tfig, ax = plt.subplots(len(labels),3,figsize=(10,70))\n",
    "\n",
    "\tfor i,(input_image, heatmap, label, info) in enumerate(zip(temp_input_images, temp_heatmaps, temp_labels, infos)):\n",
    "\n",
    "\n",
    "\t\tinput_image = to_pil_image(input_image)\n",
    "\t\ttotal_heatmap = torch.zeros(heatmap.shape[1:])\n",
    "\t\tfor j in range(len(heatmap)):\n",
    "\t\t\ttotal_heatmap += heatmap[j,:,:]\n",
    "\n",
    "\t\ttotal_label = torch.zeros(heatmap.shape[1:])\n",
    "\t\tfor j in range(len(label)):\n",
    "\t\t\ttotal_label += label[j,:,:]\n",
    "\n",
    "\t\tax[i][0].set_title(info.split(split_token)[-1])\n",
    "\t\tax[i][0].imshow(input_image)\n",
    "\t\tax[i][1].set_title('pred_heatmap')\n",
    "\t\tax[i][1].imshow(total_heatmap)\n",
    "\t\tax[i][2].set_title('heatmap_GT')\n",
    "\t\tax[i][2].imshow(total_label)\n",
    "\n",
    "\t# plt.show()\n",
    "\n",
    "\treturn fig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_dir, model_dir, args, logging=True):\n",
    "\tseed_everything(args.seed)\n",
    "\tif logging:wandb.init(project=\"2d to 3d\", entity=\"vhehduatks\")\n",
    "\n",
    "\tsave_dir = increment_path(os.path.join(model_dir, args.name))\n",
    "\tprint(save_dir)\n",
    "\tos.makedirs(save_dir)\n",
    "\t# -- settings\n",
    "\n",
    "\n",
    "\t# -- dataset\n",
    "\tdataset_module = getattr(import_module(\"dataset\"), args.dataset) \n",
    "\tdataset = dataset_module(\n",
    "\t\tdataroot=data_dir,\n",
    "\t)\n",
    "\t# num_classes = dataset.num_classes  # 18\n",
    "\n",
    "\t# -- augmentation\n",
    "\t# transform_module = getattr(import_module(\"dataset\"), args.augmentation)  # default: BaseAugmentation\n",
    "\t# transform = transform_module(\n",
    "\t#     resize=args.resize,\n",
    "\t#     # mean=dataset.mean,\n",
    "\t#     # std=dataset.std,\n",
    "\t# )\n",
    "\t# dataset.set_transform(transform)\n",
    "\n",
    "\t# -- data_loader\n",
    "\ttrain_set, val_set = dataset.split_dataset()\n",
    "\n",
    "\ttrain_loader = DataLoader(\n",
    "\t\ttrain_set,\n",
    "\t\tbatch_size=args.batch_size,\n",
    "\t\tnum_workers=multiprocessing.cpu_count() // 2,\n",
    "\t\t# num_workers= 0,\n",
    "\t\tshuffle=True,\n",
    "\t\tpin_memory=use_cuda,\n",
    "\t\tdrop_last=True,\n",
    "\t)\n",
    "\n",
    "\tval_loader = DataLoader(\n",
    "\t\tval_set,\n",
    "\t\tbatch_size=args.valid_batch_size,\n",
    "\t\tnum_workers=multiprocessing.cpu_count() // 2,\n",
    "\t\t# num_workers= 0,\n",
    "\t\tshuffle=False,\n",
    "\t\tpin_memory=use_cuda,\n",
    "\t\tdrop_last=True,\n",
    "\t)\n",
    "\n",
    "\t# # -- feature_model\n",
    "\t# feature_model = get_pose_net(True)\n",
    "\t# feature_model = torch.nn.DataParallel(feature_model)\n",
    "\n",
    "\t# -- reg_model\n",
    "\tmodel_module = getattr(import_module(\"model\"), args.model)  # default: BaseModel\n",
    "\tmodel = model_module().to(device)\n",
    "\tmodel = torch.nn.DataParallel(model,device_ids=[0,1])\n",
    "\n",
    "\n",
    "\t# -- loss & metric\n",
    "\t# smpl_criterion = create_criterion(args.criterion_1)\n",
    "\tdepth_criterion = create_criterion(args.criterion_2)   # MSE\n",
    "\tprojection_criterion = create_criterion(args.criterion_3) # L1\n",
    "\tcam_criterion = create_criterion(args.criterion_4) # MSE\n",
    "\tjoint_3d_criterion = create_criterion(args.criterion_5) # MSE\n",
    "\theatmap_criterion = create_criterion(args.criterion_6) # MSE\n",
    "\theatmap_proj_criterion = create_criterion(args.criterion_7)\n",
    "\n",
    "\t# opt_module = getattr(import_module(\"torch.optim\"), args.optimizer)  # default: SGD\n",
    "\toptimizer = torch.optim.Adam(\n",
    "\t\tparams=model.parameters(),\n",
    "\t\tlr=args.lr,# 0.001\n",
    "\t\tweight_decay=5e-4\n",
    "\t)\n",
    "\tscheduler = StepLR(optimizer, args.lr_decay_step, gamma=0.5)\n",
    "\t# scheduler = LambdaLR(optimizer,lambda epoch: 0.65 ** epoch)\n",
    "\t# -- logging\n",
    "\t# logger = SummaryWriter(log_dir=save_dir)\n",
    "\tif logging:wandb.config=vars(args)\n",
    "\t# with open(os.path.join(save_dir, 'config.json'), 'w', encoding='utf-8') as f:\n",
    "\t#     json.dump(vars(args), f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\t# best_val_acc = 0\n",
    "\tbest_val_loss = np.inf\n",
    "\n",
    "\tfor epoch in range(args.epochs):\n",
    "\t\t# train loop\n",
    "\t\tmodel.train()\n",
    "\t\t\n",
    "\t\tloss_value = 0\n",
    "\t\tmatches = 0\n",
    "\t\tfor idx, train_batch in enumerate(train_loader):\n",
    "\t\t\ttotal_loss={}\n",
    "\t\t\tret_dict_train = train_batch\n",
    "\t\t\tinputs = {\n",
    "\t\t\t\t'image' : ret_dict_train['image'].cuda(),\n",
    "\t\t\t\t'depth' : ret_dict_train['depth'].cuda(),\n",
    "\t\t\t\t'heatmap' : ret_dict_train['heatmap'].cuda(),\n",
    "\t\t\t\t'camera_info' : ret_dict_train['camera_info']\n",
    "\t\t\t}\n",
    "\t\t\t# joint_2d_labels = ret_dict_train['joints_2d'].to(device)\n",
    "\t\t\tjoint_3d_labels = ret_dict_train['joints_3d_cam'].to(device)\n",
    "\t\t\tdepth_labels = ret_dict_train['depth'].to(device)\n",
    "\t\t\tcam_labels_trans,cam_labels_rot = ret_dict_train['camera_info']\n",
    "\t\t\tinfos = ret_dict_train['info']\n",
    "\t\t\tfisheye_labels = ret_dict_train['fisheye_joints_2d'].to(device)\n",
    "\t\t\theatmap_labels = ret_dict_train['heatmap'].to(device)\n",
    "\t\t\theatmap_proj_labels = ret_dict_train['heatmap_1'].to(device)\n",
    "\n",
    "\t\t\tpred_dict = model(inputs,is_train=True,epoch=epoch)\n",
    "\t\t\t\n",
    "\t\t\tdepth_loss = depth_criterion(pred_dict['depth_feature'], depth_labels)\n",
    "\t\t\t# depth_criterion.register_forward_hook(partial(nan_detect_hook, label_info=infos, label=depth_labels))\n",
    "\t\t\ttotal_loss['depth_loss']= depth_loss * 100\n",
    "\t\t\theatmap_loss = heatmap_criterion(pred_dict['heatmap'],heatmap_labels)\n",
    "\t\t\t# heatmap_criterion.register_forward_hook(partial(nan_detect_hook,label_info=infos, label = heatmap_labels))\n",
    "\t\t\ttotal_loss['heatmap_loss'] = heatmap_loss * 1000\n",
    "\t\t\t\n",
    "\t\t\tcam_loss_trans = cam_criterion(pred_dict['regressor2_dict']['pred_trans'],cam_labels_trans.to(device))\n",
    "\t\t\tcam_loss_rot = cam_criterion(pred_dict['regressor2_dict']['pred_rot'],cam_labels_rot.to(device))\n",
    "\t\t\t# cam_criterion.register_forward_hook(partial(nan_detect_hook,label_info=infos, label = cam_labels_trans))\n",
    "\t\t\ttotal_loss['cam_loss'] = ((cam_loss_trans * 0.01) + (cam_loss_rot * 1))/2\n",
    "\n",
    "\t\t\tfisheye_projection_2d_loss = projection_criterion(pred_dict['regressor2_dict']['fisheye_kp_2d'],fisheye_labels)\n",
    "\t\t\t# projection_criterion.register_forward_hook(partial(nan_detect_hook,label_info=infos, label = fisheye_labels))\n",
    "\t\t\ttotal_loss['projection_2d_loss'] = fisheye_projection_2d_loss * 0.1\n",
    "\n",
    "\t\t\theatmap_projection_loss = heatmap_proj_criterion(pred_dict['regressor2_dict']['pred_heatmap_smpl'],heatmap_proj_labels)\n",
    "\t\t\ttotal_loss['heatmap_projection_loss'] = heatmap_projection_loss * 1000\n",
    "\n",
    "\t\t\tjoint_3d_loss = joint_3d_criterion(pred_dict['regressor2_dict']['kp_3d_cam'],joint_3d_labels)\n",
    "\t\t\t# joint_3d_criterion.register_forward_hook(partial(nan_detect_hook,label_info=infos, label = joint_3d_labels))\n",
    "\t\t\ttotal_loss['joint_3d_loss'] = joint_3d_loss * 0.01\n",
    "\t\t\t\n",
    "\n",
    "\n",
    "\t\t\t# fisheye_cam_trans_loss = cam_criterion(pred_dict['regressor1_dict']['pred_trans'],cam_labels_trans.to(device))\n",
    "\t\t\t# fisheye_cam_rot_loss = cam_criterion(pred_dict['regressor1_dict']['pred_rot'],cam_labels_rot.to(device))\n",
    "\t\t\t# total_loss['fisheye_cam_loss'] = (fisheye_cam_trans_loss * 0.01 + fisheye_cam_rot_loss * 1)/2\n",
    "\n",
    "\n",
    "\t\t\tloss = torch.stack(list(total_loss.values())).sum()\n",
    "\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\tscheduler.step()\n",
    "\t\t\t\n",
    "\t\t\t# loss_value += loss.item()\n",
    "\t\t\t# matches += (preds == labels).sum().item()\n",
    "\t\t\tif (idx + 1) % args.log_interval == 0:\n",
    "\t\t\t\t# train_loss = loss_value / args.log_interval\n",
    "\t\t\t\t# train_acc = matches / args.batch_size / args.log_interval\n",
    "\t\t\t\tcurrent_lr = get_lr(optimizer)\n",
    "\t\t\t\tprint(\"=======================================================================\")\n",
    "\t\t\t\tfor loss_name,val in total_loss.items():\n",
    "\t\t\t\t\tprint(\n",
    "\t\t\t\t\t\tf\"Epoch[{epoch}/{args.epochs}]({idx + 1}/{len(train_loader)}) || \"\n",
    "\t\t\t\t\t\tf\"training loss : {loss_name} : {val:4.4} || lr {current_lr}\"\n",
    "\t\t\t\t\t\t# f\"training loss {train_loss:4.4} || training accuracy {train_acc:4.2%} || lr {current_lr}\"\n",
    "\t\t\t\t\t)\n",
    "\t\t\t\t\tif logging:\n",
    "\t\t\t\t\t\twandb.log({\n",
    "\t\t\t\t\t\t\t'train/'+loss_name : val,\n",
    "\t\t\t\t\t\t\t\"train/lr\" : current_lr,\n",
    "\t\t\t\t\t\t\t\"train/Epoch\" : epoch    \n",
    "\t\t\t\t\t\t\t})\n",
    "\t\t\t# viewer(outs)\n",
    "\t\t\tif (idx + 1) % 300 == 0:\n",
    "\t\t\t\t# fig2 = viewer(outs,joint_labels,infos)\n",
    "\t\t\t\tfig_dict = {\n",
    "\t\t\t\t'depth_feature_fig' : depth_viewer(inputs['image'],pred_dict['depth_feature'],depth_labels,infos),\n",
    "\t\t\t\t# 'joint_2d_fig' : joint_2d_viewer(inputs['image'], pred_dict['regressor2_res_dict']['kp_2d'],joint_2d_labels,infos),\n",
    "\t\t\t\t'fisheye_2d_fig' : fisheye_joint_2d_viewer(inputs['image'],pred_dict['regressor2_dict']['fisheye_kp_2d'],fisheye_labels,infos),\n",
    "\t\t\t\t'heatmap_fig' : heatmap_viewer(inputs['image'],pred_dict['heatmap'],heatmap_labels,infos),\n",
    "\t\t\t\t'joint_3d_fig' : joint_3d_viewer(inputs['image'],pred_dict['regressor2_dict']['kp_3d_cam'],joint_3d_labels,infos),\n",
    "\t\t\t\t'heatmap_smpl_fig' : heatmap_viewer(inputs['image'],pred_dict['regressor2_dict']['pred_heatmap_smpl'],heatmap_proj_labels,infos)\n",
    "\t\t\t\t\n",
    "\t\t\t\t}\n",
    "\t\t\t\tif logging:\n",
    "\t\t\t\t\t#step=len(train_loader)*epoch+idx\n",
    "\t\t\t\t\twandb.log({\n",
    "\t\t\t\t\t\t\"train/depth_feature_fig\":[wandb.Image(fig_dict['depth_feature_fig'])],\n",
    "\t\t\t\t\t\t# \"joint_2d_fig_img\":[wandb.Image(joint_2d_fig)],\n",
    "\t\t\t\t\t\t\"train/fisheye_2d_fig\":[wandb.Image(fig_dict['fisheye_2d_fig'])],\n",
    "\t\t\t\t\t\t\"train/heatmap_fig\":[wandb.Image(fig_dict['heatmap_fig'])],\n",
    "\t\t\t\t\t\t\"train/joint_3d_fig\":[wandb.Image(fig_dict['joint_3d_fig'])],\n",
    "\t\t\t\t\t\t\"train/heatmap_smpl_fig\":[wandb.Image(fig_dict['heatmap_smpl_fig'])],\n",
    "\t\t\t\t\t})\n",
    "\t\t\t\tfor key,val in fig_dict.items():\n",
    "\t\t\t\t\tplt.close(val)\n",
    "\t\t\t# logger.add_scalar(\"Train/loss\", train_loss, epoch * len(train_loader) + idx)\n",
    "\t\t\t# logger.add_scalar(\"Train/accuracy\", train_acc, epoch * len(train_loader) + idx)\n",
    "\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t# val loop\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tprint(\"Calculating validation results...\")\n",
    "\t\t\tmodel.eval()\n",
    "\t\t\tfor val_idx,val_batch in enumerate(val_loader):\n",
    "\t\t\t\ttotal_loss={}\n",
    "\t\t\t\tret_dict_train = val_batch\n",
    "\t\t\t\tinputs = {\n",
    "\t\t\t\t'image':ret_dict_train['image'].cuda(),\n",
    "\t\t\t\t'depth':ret_dict_train['depth'].cuda(),\n",
    "\t\t\t\t'heatmap':ret_dict_train['heatmap'].cuda(),\n",
    "\t\t\t\t'camera_info':ret_dict_train['camera_info']\n",
    "\t\t\t\t}\n",
    "\t\t\t\t# joint_2d_labels = ret_dict_train['joints_2d'].to(device)\n",
    "\t\t\t\tjoint_3d_labels = ret_dict_train['joints_3d_cam'].to(device)\n",
    "\t\t\t\tdepth_labels = ret_dict_train['depth'].to(device)\n",
    "\t\t\t\tcam_labels_trans,cam_labels_rot = ret_dict_train['camera_info']\n",
    "\t\t\t\tinfos = ret_dict_train['info']\n",
    "\t\t\t\tfisheye_labels = ret_dict_train['fisheye_joints_2d'].to(device)\n",
    "\t\t\t\theatmap_labels = ret_dict_train['heatmap'].to(device)\n",
    "\t\t\t\theatmap_proj_labels = ret_dict_train['heatmap_1'].to(device)\n",
    "\n",
    "\t\t\t\tpred_dict = model(inputs,is_train=False,epoch=epoch)\n",
    "\n",
    "\t\t\t\tdepth_loss = depth_criterion(pred_dict['depth_feature'], depth_labels)\n",
    "\t\t\t\t# depth_criterion.register_forward_hook(partial(nan_detect_hook, label_info=infos, label=depth_labels))\n",
    "\t\t\t\ttotal_loss['depth_loss']= depth_loss * 100\n",
    "\t\t\t\theatmap_loss = heatmap_criterion(pred_dict['heatmap'],heatmap_labels)\n",
    "\t\t\t\t# heatmap_criterion.register_forward_hook(partial(nan_detect_hook,label_info=infos, label = heatmap_labels))\n",
    "\t\t\t\ttotal_loss['heatmap_loss'] = heatmap_loss * 1000\n",
    "\t\t\t\t\n",
    "\t\t\t\tcam_loss_trans = cam_criterion(pred_dict['regressor2_dict']['pred_trans'],cam_labels_trans.to(device))\n",
    "\t\t\t\tcam_loss_rot = cam_criterion(pred_dict['regressor2_dict']['pred_rot'],cam_labels_rot.to(device))\n",
    "\t\t\t\t# cam_criterion.register_forward_hook(partial(nan_detect_hook,label_info=infos, label = cam_labels_trans))\n",
    "\t\t\t\ttotal_loss['cam_loss'] = ((cam_loss_trans * 0.01) + (cam_loss_rot * 1))/2\n",
    "\n",
    "\t\t\t\tfisheye_projection_2d_loss = projection_criterion(pred_dict['regressor2_dict']['fisheye_kp_2d'],fisheye_labels)\n",
    "\t\t\t\t# projection_criterion.register_forward_hook(partial(nan_detect_hook,label_info=infos, label = fisheye_labels))\n",
    "\t\t\t\ttotal_loss['projection_2d_loss'] = fisheye_projection_2d_loss * 0.1\n",
    "\n",
    "\t\t\t\theatmap_projection_loss = heatmap_proj_criterion(pred_dict['regressor2_dict']['pred_heatmap_smpl'],heatmap_proj_labels)\n",
    "\t\t\t\ttotal_loss['heatmap_projection_loss'] = heatmap_projection_loss * 1000\n",
    "\n",
    "\t\t\t\tjoint_3d_loss = joint_3d_criterion(pred_dict['regressor2_dict']['kp_3d_cam'],joint_3d_labels)\n",
    "\t\t\t\t# joint_3d_criterion.register_forward_hook(partial(nan_detect_hook,label_info=infos, label = joint_3d_labels))\n",
    "\t\t\t\ttotal_loss['joint_3d_loss'] = joint_3d_loss * 0.01\n",
    "\n",
    "\n",
    "\t\t\t\t# fisheye_cam_trans_loss = cam_criterion(pred_dict['regressor1_dict']['pred_trans'],cam_labels_trans.to(device))\n",
    "\t\t\t\t# fisheye_cam_rot_loss = cam_criterion(pred_dict['regressor1_dict']['pred_rot'],cam_labels_rot.to(device))\n",
    "\t\t\t\t# total_loss['fisheye_cam_loss'] = (fisheye_cam_trans_loss * 0.01 + fisheye_cam_rot_loss * 1)/2\n",
    "\n",
    "\t\t  \n",
    "\n",
    "\t\t\t\tloss = torch.stack(list(total_loss.values())).sum()\n",
    "\n",
    "\t\t\t\tif (val_idx + 1) % args.log_interval == 0:\n",
    "\t\t \n",
    "\t\t\t\t\tcurrent_lr = get_lr(optimizer)\n",
    "\t\t\t\t\tprint(\"=======================================================================\")\n",
    "\t\t\t\t\tfor loss_name,value in total_loss.items():\n",
    "\t\t\t\t\t\tloss_name = 'val_'+loss_name\n",
    "\t\t\t\t\t\tprint(\n",
    "\t\t\t\t\t\t\tf\"val_Epoch[{epoch}/{args.epochs}]({val_idx + 1}/{len(val_loader)}) || \"\n",
    "\t\t\t\t\t\t\tf\"val_training loss : {loss_name} : {value:4.4} || lr {current_lr}\"\n",
    "\t\t\t\t\t\t\t# f\"training loss {train_loss:4.4} || training accuracy {train_acc:4.2%} || lr {current_lr}\"\n",
    "\t\t\t\t\t\t)\n",
    "\t\t\t\t\t\tif logging:\n",
    "\t\t\t\t\t\t\twandb.log({\n",
    "\t\t\t\t\t\t\t\t'val/'+loss_name : value,\n",
    "\t\t\t\t\t\t\t\t\"val/lr\" : current_lr,\n",
    "\t\t\t\t\t\t\t\t\"val/Epoch\" : epoch    \n",
    "\t\t\t\t\t\t\t\t})\n",
    "\t\t\t\t\t\t \n",
    "\t\t\t\tif (val_idx + 1) % 300 == 0:\n",
    "\t\t\t\t\t# fig2 = viewer(outs,joint_labels,infos)\n",
    "\t\t\t\t\tval_fig_dict = {\n",
    "\t\t\t\t\t'depth_feature_fig' : depth_viewer(inputs['image'],pred_dict['depth_feature'],depth_labels,infos),\n",
    "\t\t\t\t\t# 'joint_2d_fig' : joint_2d_viewer(inputs['image'], pred_dict['regressor2_dict']['kp_2d'],joint_2d_labels,infos),\n",
    "\t\t\t\t\t'fisheye_2d_fig' : fisheye_joint_2d_viewer(inputs['image'],pred_dict['regressor2_dict']['fisheye_kp_2d'],fisheye_labels,infos),\n",
    "\t\t\t\t\t'heatmap_fig' : heatmap_viewer(inputs['image'],pred_dict['heatmap'],heatmap_labels,infos),\n",
    "\t\t\t\t\t'joint_3d_fig' : joint_3d_viewer(inputs['image'],pred_dict['regressor2_dict']['kp_3d_cam'],joint_3d_labels,infos),\n",
    "\t\t\t\t\t'heatmap_smpl_fig' : heatmap_viewer(inputs['image'],pred_dict['regressor2_dict']['pred_heatmap_smpl'],heatmap_proj_labels,infos),\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t\tif logging:\n",
    "\t\t\t\t\t\twandb.log({\n",
    "\t\t\t\t\t\t\t\"val/depth_feature_fig\":[wandb.Image(val_fig_dict['depth_feature_fig'])],\n",
    "\t\t\t\t\t\t\t# \"joint_2d_fig_img\":[wandb.Image(joint_2d_fig)],\n",
    "\t\t\t\t\t\t\t\"val/fisheye_2d_fig\":[wandb.Image(fig_dict['fisheye_2d_fig'])],\n",
    "\t\t\t\t\t\t\t\"val/heatmap_fig\":[wandb.Image(val_fig_dict['heatmap_fig'])],\n",
    "\t\t\t\t\t\t\t\"val/joint_3d_fig\":[wandb.Image(val_fig_dict['joint_3d_fig'])],\n",
    "\t\t\t\t\t\t\t\"val/heatmap_smpl_fig\":[wandb.Image(fig_dict['heatmap_smpl_fig'])],\n",
    "\t\t\t\t\t\t})\n",
    "\t\t\t\t\tfor key,val in val_fig_dict.items():\n",
    "\t\t\t\t\t\tplt.close(val)\n",
    "\t\t\t\t\tif best_val_loss>loss:\n",
    "\t\t\t\t\t\ttorch.save(model.module.state_dict(), f\"{save_dir}{split_token}best.pth\")\n",
    "\t\t\t\t\t\tbest_val_loss = loss\n",
    "\t\t\t\t\ttorch.save(model.module.state_dict(), f\"{save_dir}{split_token}last.pth\")\n",
    "\twandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dataset/egodataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvhehduatks\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/2d_to_3d/apps/wandb/run-20230502_071802-kslamr8b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vhehduatks/2d%20to%203d/runs/kslamr8b' target=\"_blank\">lucky-water-323</a></strong> to <a href='https://wandb.ai/vhehduatks/2d%20to%203d' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vhehduatks/2d%20to%203d' target=\"_blank\">https://wandb.ai/vhehduatks/2d%20to%203d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vhehduatks/2d%20to%203d/runs/kslamr8b' target=\"_blank\">https://wandb.ai/vhehduatks/2d%20to%203d/runs/kslamr8b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/2d_to_3d/apps/exp369\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model_dir \u001b[39m=\u001b[39m args\u001b[39m.\u001b[39mmodel_dir\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(data_dir)\n\u001b[0;32m----> 5\u001b[0m train(data_dir, model_dir, args)\n",
      "Cell \u001b[0;32mIn[8], line 56\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(data_dir, model_dir, args, logging)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m# # -- feature_model\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39m# feature_model = get_pose_net(True)\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[39m# feature_model = torch.nn.DataParallel(feature_model)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \n\u001b[1;32m     54\u001b[0m \u001b[39m# -- reg_model\u001b[39;00m\n\u001b[1;32m     55\u001b[0m model_module \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(import_module(\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m), args\u001b[39m.\u001b[39mmodel)  \u001b[39m# default: BaseModel\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m model \u001b[39m=\u001b[39m model_module()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     57\u001b[0m model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mDataParallel(model,device_ids\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m])\n\u001b[1;32m     60\u001b[0m \u001b[39m# -- loss & metric\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[39m# smpl_criterion = create_criterion(args.criterion_1)\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/2d_to_3d/apps/model.py:42\u001b[0m, in \u001b[0;36mTempModel.__init__\u001b[0;34m(self, pretrained_path)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregressor2\u001b[39m=\u001b[39mRegressor2(depthmapfeat_dim\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m,heatmapfeat_dim\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m,smpl_mean_params\u001b[39m=\u001b[39mSMPL_MEAN_PARAMS)\n\u001b[1;32m     41\u001b[0m \u001b[39mif\u001b[39;00m pretrained_path:\n\u001b[0;32m---> 42\u001b[0m \ttempmodel_ckpt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(pretrained_path)\n\u001b[1;32m     43\u001b[0m \t\u001b[39mif\u001b[39;00m only_resnet:\n\u001b[1;32m     44\u001b[0m \t\tfeature_model1_state_dict \u001b[39m=\u001b[39m OrderedDict()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:789\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    788\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 789\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    790\u001b[0m \u001b[39mif\u001b[39;00m weights_only:\n\u001b[1;32m    791\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:1131\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1130\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1131\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1133\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1135\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:1101\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m loaded_storages:\n\u001b[1;32m   1100\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1101\u001b[0m     load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[1;32m   1103\u001b[0m \u001b[39mreturn\u001b[39;00m loaded_storages[key]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:1083\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1079\u001b[0m storage \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[39m.\u001b[39mUntypedStorage)\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39muntyped()\n\u001b[1;32m   1080\u001b[0m \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[39m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1082\u001b[0m loaded_storages[key] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1083\u001b[0m     wrap_storage\u001b[39m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1084\u001b[0m     dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:215\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 215\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[1;32m    216\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:182\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    181\u001b[0m     \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 182\u001b[0m         device \u001b[39m=\u001b[39m validate_cuda_device(location)\n\u001b[1;32m    183\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m_torch_load_uninitialized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    184\u001b[0m             \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:166\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    163\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_get_device_index(location, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    165\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m--> 166\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAttempting to deserialize object on a CUDA \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    168\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mIf you are running on a CPU-only machine, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    169\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcpu\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    170\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mto map your storages to the CPU.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    171\u001b[0m device_count \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "data_dir = args.data_dir\n",
    "model_dir = args.model_dir\n",
    "print(data_dir)\n",
    "\n",
    "train(data_dir, model_dir, args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('smplx')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b6491936ae5e9232e741cb0cf3bc3536e77224e6d1117105f3d0df307ba3b0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
